# Paper Title: *ANALYZING THE LANGUAGE OF VISUAL TOKENS*  
take a natural-language-centric approach to analyzing discrete visual languages and uncover striking similarities and fundamental differences.

---

## 1. Summary
- **Problem Addressed**: Answer the difference between visual tokens and language tokens
- **Key Idea/Method**: None
---



---

## 3. Key Takeaways
- The high vocabulary diversity of visual tokens means that while generative models will be able to generate higher-fidelity output, discriminative models are at high risk of over-fitting
- NATURALITY: Chameleon tokenizer, is by far the most natural in Figure 5a, suggesting that tokenizations performing well for vision-text tasks might have more natural distributions
- ENTROPY AND REDUNDANCY: In general, the average code length, entropy, and bits of information/sample are higher for visual languages,Models like LLaVA  with simple projection layers between the visual token and text token spaces may not perform well. mPlug  have more dense
transformer-based adapters  perform well
---

\
